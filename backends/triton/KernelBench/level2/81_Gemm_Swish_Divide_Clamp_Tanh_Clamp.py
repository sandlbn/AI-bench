# ruff: noqa: E731
# AUTOGENERATED KERNEL (LLM)
# Source: LLM-generated candidate implementation
# Status: Experimental / uncurated
# Expectation: Correctness-first, performance not representative

import math

import torch
import torch.nn as nn
import triton
import triton.language as tl


# ---------------------------------------------------------------------
# Triton kernel: GEMM + bias
#   Y = X @ W^T + b
#
# X: [M, K]
# W: [N, K]
# b: [N]
# Y: [M, N]
# ---------------------------------------------------------------------
@triton.jit
def _linear_kernel(
    in_ptr,
    wt_ptr,
    bias_ptr,
    out_ptr,
    M,
    N,
    K,
    stride_in0,
    stride_in1,
    stride_w0,
    stride_w1,
    stride_out0,
    stride_out1,
    stride_bias,
    BLOCK_M: tl.constexpr,
    BLOCK_N: tl.constexpr,
    BLOCK_K: tl.constexpr,
):
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    mask_m = offs_m < M
    mask_n = offs_n < N

    # accumulator in fp64 (as in your original code)
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float64)

    for k_start in range(0, K, BLOCK_K):
        offs_k = k_start + tl.arange(0, BLOCK_K)
        mask_k = offs_k < K

        # X block: [BLOCK_M, BLOCK_K]
        in_ptrs = in_ptr + offs_m[:, None] * stride_in0 + offs_k[None, :] * stride_in1
        a_fp32 = tl.load(
            in_ptrs,
            mask=mask_m[:, None] & mask_k[None, :],
            other=0.0,
        )
        a = a_fp32.to(tl.float64)

        # W block (logical W^T): [BLOCK_K, BLOCK_N]
        wt_ptrs = wt_ptr + offs_n[:, None] * stride_w0 + offs_k[None, :] * stride_w1
        b_fp32 = tl.load(
            wt_ptrs,
            mask=mask_n[:, None] & mask_k[None, :],
            other=0.0,
        )
        b = b_fp32.T.to(tl.float64)  # transpose to [BLOCK_K, BLOCK_N]

        acc = tl.dot(a, b, acc)

    # Add bias (broadcast over rows)
    bias_fp32 = tl.load(
        bias_ptr + offs_n * stride_bias,
        mask=mask_n,
        other=0.0,
    )
    bias64 = bias_fp32.to(tl.float64)
    acc = acc + bias64[None, :]

    out_val = acc.to(tl.float32)
    out_ptrs = out_ptr + offs_m[:, None] * stride_out0 + offs_n[None, :] * stride_out1
    tl.store(out_ptrs, out_val, mask=mask_m[:, None] & mask_n[None, :])


# ---------------------------------------------------------------------
# Triton kernel: Swish → /2 → clamp → tanh → clamp
#
# Operates row-wise over Y (M rows, N columns)
# ---------------------------------------------------------------------
@triton.jit
def _swish_div_clamp_tanh_kernel(
    inp_ptr,
    out_ptr,
    M,
    N,
    stride_row,
    stride_col,
    BLOCK_SIZE: tl.constexpr,
):
    pid_col = tl.program_id(0)
    pid_row = tl.program_id(1)

    col_offsets = pid_col * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)
    mask = col_offsets < N

    row_start = pid_row * stride_row

    ptrs_in = inp_ptr + row_start + col_offsets * stride_col
    ptrs_out = out_ptr + row_start + col_offsets * stride_col

    x = tl.load(ptrs_in, mask=mask, other=0.0)

    # swish: x * sigmoid(x)
    exp_neg_x = tl.math.exp(-x)
    sig = 1.0 / (1.0 + exp_neg_x)
    swish = x * sig

    # divide by 2
    half = swish * 0.5

    # clamp [-1, 1]
    c1 = tl.maximum(half, -1.0)
    c1 = tl.minimum(c1, 1.0)

    # tanh
    exp_p = tl.math.exp(c1)
    exp_n = tl.math.exp(-c1)
    t = (exp_p - exp_n) / (exp_p + exp_n)

    # final clamp [-1, 1]
    outv = tl.maximum(t, -1.0)
    outv = tl.minimum(outv, 1.0)

    tl.store(ptrs_out, outv, mask=mask)


# ---------------------------------------------------------------------
# Low-level fused Triton wrapper (XPU, dtype-flexible)
# ---------------------------------------------------------------------
def _gemm_swish_div_clamp_tanh_clamp_xpu(
    x: torch.Tensor,
    weight: torch.Tensor,
    bias: torch.Tensor,
) -> torch.Tensor:
    """
    XPU-only fused pipeline:

        y = x @ W^T + b
        y = y * sigmoid(y)     # Swish
        y = y / 2
        y = clamp(y, -1, 1)
        y = tanh(y)
        y = clamp(y, -1, 1)

    Accepts any floating dtype (fp16/bf16/fp32),
    computes in fp32, returns in x.dtype.
    """
    if not (hasattr(torch, "xpu") and torch.xpu.is_available()):
        raise RuntimeError("XPU device is not available")

    if x.device.type != "xpu":
        raise RuntimeError(f"Expected x on 'xpu', got {x.device}")
    if weight.device != x.device or bias.device != x.device:
        raise RuntimeError("weight and bias must be on the same XPU as x")

    if not (
        x.is_floating_point()
        and weight.is_floating_point()
        and bias.is_floating_point()
    ):
        raise TypeError("x, weight, and bias must be floating point tensors")

    if x.ndim != 2:
        raise ValueError(f"Expected x.ndim == 2, got {x.ndim}")
    if weight.ndim != 2 or bias.ndim != 1:
        raise ValueError("Expected weight.ndim == 2 and bias.ndim == 1")

    M, K = x.shape
    N, K2 = weight.shape
    if K2 != K:
        raise ValueError(f"Weight K dim {K2} != x K dim {K}")
    if bias.numel() != N:
        raise ValueError(f"Bias length {bias.numel()} != output dim {N}")

    orig_dtype = x.dtype

    # Work in fp32 for numerical stability
    x32 = x.to(torch.float32).contiguous()
    w32 = weight.to(torch.float32).contiguous()
    b32 = bias.to(torch.float32).contiguous()

    # GEMM + bias
    linear_out = torch.empty((M, N), device=x.device, dtype=torch.float32)

    stride_in0, stride_in1 = x32.stride()
    stride_w0, stride_w1 = w32.stride()
    stride_out0, stride_out1 = linear_out.stride()
    stride_bias = b32.stride()[0]

    BLOCK_M, BLOCK_N, BLOCK_K = 64, 64, 64
    grid_lin = (triton.cdiv(M, BLOCK_M), triton.cdiv(N, BLOCK_N))

    _linear_kernel[grid_lin](
        x32,
        w32,
        b32,
        linear_out,
        M,
        N,
        K,
        stride_in0,
        stride_in1,
        stride_w0,
        stride_w1,
        stride_out0,
        stride_out1,
        stride_bias,
        BLOCK_M=BLOCK_M,
        BLOCK_N=BLOCK_N,
        BLOCK_K=BLOCK_K,
    )

    # Swish → /2 → clamp → tanh → clamp
    final_out = torch.empty_like(linear_out)
    stride_row, stride_col = linear_out.stride()
    BLOCK_SIZE = 256
    grid_post = (triton.cdiv(N, BLOCK_SIZE), M)

    _swish_div_clamp_tanh_kernel[grid_post](
        linear_out,
        final_out,
        M,
        N,
        stride_row,
        stride_col,
        BLOCK_SIZE=BLOCK_SIZE,
    )

    return final_out.to(orig_dtype)


# ---------------------------------------------------------------------
# KernelBench-compatible Model wrapper
#
# Matches original PyTorch reference:
#
#   class Model(nn.Module):
#       def __init__(self, in_features, out_features, bias=True):
#           ...
# ---------------------------------------------------------------------
class Model(nn.Module):
    """
    Fused Triton model for KernelBench:

        y = x @ W^T + b
        y = swish(y)
        y = y / 2
        y = clamp(y, -1, 1)
        y = tanh(y)
        y = clamp(y, -1, 1)
    """

    def __init__(self, in_features: int, out_features: int, bias: bool = True):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.use_bias = bias

        # Manual parameters instead of nn.Linear, but same initialization.
        self.weight = nn.Parameter(torch.empty(out_features, in_features))
        if bias:
            self.bias = nn.Parameter(torch.empty(out_features))
        else:
            self.bias = None

        # Kaiming uniform init, same as nn.Linear
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: [BATCH, IN_FEAT]
        returns: [BATCH, OUT_FEAT]
        """
        if x.device.type != "xpu":
            raise RuntimeError(f"Expected x on 'xpu', got {x.device}")

        if self.bias is None:
            # If bias=False, emulate zero bias
            bias = torch.zeros(self.out_features, device=x.device, dtype=x.dtype)
        else:
            bias = self.bias

        return _gemm_swish_div_clamp_tanh_clamp_xpu(x, self.weight, bias)
